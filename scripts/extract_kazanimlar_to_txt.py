"""
MEB KazanÄ±m PDF'lerinden Temiz TXT Ã‡Ä±karma Script'i

Bu script:
1. data/pdfs/kazanimlar/ klasÃ¶rÃ¼ndeki tÃ¼m PDF'leri okur
2. Azure Document Intelligence ile metin Ã§Ä±karÄ±r
3. "Ã–ÄŸrenme Ã‡Ä±ktÄ±larÄ± ve SÃ¼reÃ§ BileÅŸenleri" bÃ¶lÃ¼mÃ¼nÃ¼ parse eder
4. Her PDF iÃ§in temiz bir .txt dosyasÄ± oluÅŸturur

KullanÄ±m:
    python scripts/extract_kazanimlar_to_txt.py
    python scripts/extract_kazanimlar_to_txt.py --output data/kazanimlar_txt/
"""

import sys
import os
import re
import argparse
from pathlib import Path

# Add project root to path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from azure.ai.documentintelligence import DocumentIntelligenceClient
from azure.ai.documentintelligence.models import AnalyzeDocumentRequest
from azure.core.credentials import AzureKeyCredential
from config.settings import get_settings


def extract_text_from_pdf(pdf_path: Path, doc_client) -> str:
    """Azure Document Intelligence ile PDF'den metin Ã§Ä±kar."""
    print(f"   â””â”€ Azure Document Intelligence ile metin Ã§Ä±karÄ±lÄ±yor...")

    with open(pdf_path, 'rb') as f:
        pdf_bytes = f.read()

    poller = doc_client.begin_analyze_document(
        'prebuilt-layout',
        AnalyzeDocumentRequest(bytes_source=pdf_bytes)
    )
    result = poller.result()

    return result.content


def parse_metadata_from_filename(filename: str) -> dict:
    """Dosya adÄ±ndan metadata Ã§Ä±kar."""
    # biyoloji_10.1.pdf -> subject=biyoloji, grade=10, semester=1
    stem = Path(filename).stem
    parts = stem.split('_')

    metadata = {
        "subject": "bilinmiyor",
        "subject_code": "?",
        "grade": 0,
        "semester": 0
    }

    subject_map = {
        "biyoloji": ("Biyoloji", "BÄ°Y"),
        "matematik": ("Matematik", "M"),
        "fizik": ("Fizik", "FÄ°Z"),
        "kimya": ("Kimya", "KÄ°M"),
        "turkce": ("TÃ¼rkÃ§e", "T"),
        "tarih": ("Tarih", "TAR"),
        "cografya": ("CoÄŸrafya", "COÄ"),
    }

    if len(parts) >= 2:
        subject_lower = parts[0].lower()
        if subject_lower in subject_map:
            metadata["subject"], metadata["subject_code"] = subject_map[subject_lower]
        else:
            metadata["subject"] = parts[0].capitalize()
            metadata["subject_code"] = parts[0][:3].upper()

        grade_part = parts[1]
        if '.' in grade_part:
            grade_semester = grade_part.split('.')
            try:
                metadata["grade"] = int(grade_semester[0])
                metadata["semester"] = int(grade_semester[1])
            except (ValueError, IndexError):
                pass
        else:
            try:
                metadata["grade"] = int(grade_part)
            except ValueError:
                pass

    return metadata


def parse_kazanimlar(text: str, metadata: dict) -> list:
    """
    Metinden kazanÄ±mlarÄ± parse et.
    Sadece "Ã–ÄŸrenme Ã‡Ä±ktÄ±larÄ± ve SÃ¼reÃ§ BileÅŸenleri" bÃ¶lÃ¼mÃ¼nÃ¼ al.
    """
    kazanimlar = []

    # "Ã–ÄŸrenme Ã‡Ä±ktÄ±larÄ± ve SÃ¼reÃ§ BileÅŸenleri" bÃ¶lÃ¼mÃ¼nÃ¼ bul
    start_marker = "Ã–ÄŸrenme Ã‡Ä±ktÄ±larÄ± ve SÃ¼reÃ§ BileÅŸenleri"
    end_markers = ["Ä°Ã§erik Ã‡erÃ§evesi", "Ã–ÄŸrenme KanÄ±tlarÄ±", "Ã–ÄŸrenme-Ã–ÄŸretme"]

    start_idx = text.find(start_marker)
    if start_idx == -1:
        print("   âš ï¸ 'Ã–ÄŸrenme Ã‡Ä±ktÄ±larÄ± ve SÃ¼reÃ§ BileÅŸenleri' bÃ¶lÃ¼mÃ¼ bulunamadÄ±!")
        return kazanimlar

    # BÃ¶lÃ¼mÃ¼n sonunu bul
    end_idx = len(text)
    for marker in end_markers:
        idx = text.find(marker, start_idx + len(start_marker))
        if idx != -1 and idx < end_idx:
            end_idx = idx

    section_text = text[start_idx:end_idx]

    # Ana kazanÄ±m pattern: BÄ°Y.10.1.1. veya M.9.1.1. gibi
    # Format: KOD. BaÅŸlÄ±k
    main_pattern = r'([A-ZÄ°ÄÃœÅÃ–Ã‡]+\.\d+\.\d+\.\d+)\.\s*(.+?)(?=\n[a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]\)|\n[A-ZÄ°ÄÃœÅÃ–Ã‡]+\.\d+\.\d+\.\d+\.|\Z)'

    # Alt kazanÄ±m pattern: a) metin, b) metin, Ã§) metin
    sub_pattern = r'([a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼])\)\s*(.+?)(?=\n[a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]\)|\n[A-ZÄ°ÄÃœÅÃ–Ã‡]+\.\d+|\nÄ°Ã§erik|\nÃ–ÄŸrenme|\Z)'

    # SatÄ±r satÄ±r iÅŸle
    lines = section_text.split('\n')
    current_main = None
    current_main_title = None

    i = 0
    while i < len(lines):
        line = lines[i].strip()

        # Ana kazanÄ±m kontrolÃ¼
        main_match = re.match(r'^([A-ZÄ°ÄÃœÅÃ–Ã‡]+\.\d+\.\d+\.\d+)\.\s*(.+)$', line)
        if main_match:
            current_main = main_match.group(1)
            current_main_title = main_match.group(2).strip()
            kazanimlar.append({
                "code": current_main,
                "title": current_main_title,
                "sub_items": []
            })
            i += 1
            continue

        # Alt kazanÄ±m kontrolÃ¼
        sub_match = re.match(r'^([a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼])\)\s*(.+)$', line)
        if sub_match and kazanimlar:
            letter = sub_match.group(1)
            description = sub_match.group(2).strip()

            # Sonraki satÄ±rlarÄ± da kontrol et (devam eden aÃ§Ä±klama)
            while i + 1 < len(lines):
                next_line = lines[i + 1].strip()
                # EÄŸer yeni bir alt kazanÄ±m veya ana kazanÄ±m deÄŸilse, devamÄ±
                if not re.match(r'^[a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]\)', next_line) and not re.match(r'^[A-ZÄ°ÄÃœÅÃ–Ã‡]+\.\d+', next_line):
                    if next_line and not next_line.startswith('http') and not re.match(r'^\d+/\d+$', next_line):
                        description += ' ' + next_line
                        i += 1
                    else:
                        break
                else:
                    break

            kazanimlar[-1]["sub_items"].append({
                "letter": letter,
                "description": description
            })

        i += 1

    return kazanimlar


def format_output(kazanimlar: list, metadata: dict) -> str:
    """KazanÄ±mlarÄ± temiz formatta string'e Ã§evir."""
    lines = []

    # Header
    lines.append("=" * 80)
    lines.append(f"{metadata['subject'].upper()} {metadata['grade']}. SINIF - {metadata['semester']}. DÃ–NEM")
    lines.append("KAZANIM LÄ°STESÄ° (Ã–ÄŸrenme Ã‡Ä±ktÄ±larÄ± ve SÃ¼reÃ§ BileÅŸenleri)")
    lines.append("=" * 80)
    lines.append("")

    # KazanÄ±mlar
    total_sub = 0
    for kaz in kazanimlar:
        lines.append(f"{kaz['code']}. {kaz['title']}")
        for sub in kaz['sub_items']:
            lines.append(f"    {sub['letter']}) {sub['description']}")
            total_sub += 1
        lines.append("")

    # Summary
    lines.append("=" * 80)
    lines.append("Ã–ZET")
    lines.append("=" * 80)
    lines.append(f"Toplam Ana KazanÄ±m: {len(kazanimlar)}")
    lines.append(f"Toplam Alt KazanÄ±m: {total_sub}")
    lines.append("")
    lines.append("KazanÄ±m DaÄŸÄ±lÄ±mÄ±:")
    for kaz in kazanimlar:
        sub_letters = ", ".join([s['letter'] for s in kaz['sub_items']])
        lines.append(f"  - {kaz['code']}: {len(kaz['sub_items'])} alt kazanÄ±m ({sub_letters})")
    lines.append("=" * 80)

    return "\n".join(lines)


def process_single_pdf(pdf_path: Path, doc_client, output_dir: Path) -> dict:
    """Tek bir PDF'i iÅŸle ve txt oluÅŸtur."""
    print(f"\nğŸ“‘ Ä°ÅŸleniyor: {pdf_path.name}")

    # Metadata
    metadata = parse_metadata_from_filename(pdf_path.name)
    print(f"   â””â”€ Ders: {metadata['subject']}, SÄ±nÄ±f: {metadata['grade']}, DÃ¶nem: {metadata['semester']}")

    # Metin Ã§Ä±kar
    text = extract_text_from_pdf(pdf_path, doc_client)
    print(f"   â””â”€ {len(text)} karakter metin Ã§Ä±karÄ±ldÄ±")

    # KazanÄ±mlarÄ± parse et
    kazanimlar = parse_kazanimlar(text, metadata)
    total_sub = sum(len(k['sub_items']) for k in kazanimlar)
    print(f"   â””â”€ {len(kazanimlar)} ana kazanÄ±m, {total_sub} alt kazanÄ±m bulundu")

    # Format ve kaydet
    output_text = format_output(kazanimlar, metadata)

    output_filename = pdf_path.stem + "_kazanimlar.txt"
    output_path = output_dir / output_filename

    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(output_text)

    print(f"   â””â”€ âœ… Kaydedildi: {output_path}")

    return {
        "file": pdf_path.name,
        "main_count": len(kazanimlar),
        "sub_count": total_sub,
        "output": str(output_path)
    }


def main():
    parser = argparse.ArgumentParser(
        description="MEB KazanÄ±m PDF'lerinden temiz TXT Ã§Ä±karma",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    parser.add_argument(
        "--input", "-i",
        type=str,
        default="data/pdfs/kazanimlar",
        help="KazanÄ±m PDF'lerinin bulunduÄŸu klasÃ¶r (varsayÄ±lan: data/pdfs/kazanimlar)"
    )

    parser.add_argument(
        "--output", "-o",
        type=str,
        default="data/kazanimlar_txt",
        help="Ã‡Ä±ktÄ± TXT dosyalarÄ±nÄ±n kaydedileceÄŸi klasÃ¶r (varsayÄ±lan: data/kazanimlar_txt)"
    )

    parser.add_argument(
        "--file", "-f",
        type=str,
        help="Sadece belirli bir PDF'i iÅŸle"
    )

    args = parser.parse_args()

    print("=" * 60)
    print("MEB KazanÄ±m PDF -> TXT Ã‡Ä±karma")
    print("=" * 60)

    # Azure client
    settings = get_settings()
    doc_client = DocumentIntelligenceClient(
        endpoint=settings.documentintelligence_endpoint,
        credential=AzureKeyCredential(settings.documentintelligence_api_key)
    )

    # Output klasÃ¶rÃ¼
    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)

    # PDF'leri bul
    if args.file:
        pdf_files = [Path(args.file)]
    else:
        input_dir = Path(args.input)
        pdf_files = list(input_dir.glob("*.pdf"))

    if not pdf_files:
        print("âš ï¸ PDF dosyasÄ± bulunamadÄ±!")
        return

    print(f"\nğŸ“š {len(pdf_files)} PDF iÅŸlenecek\n")

    # Ä°ÅŸle
    results = []
    for pdf_path in pdf_files:
        try:
            result = process_single_pdf(pdf_path, doc_client, output_dir)
            results.append(result)
        except Exception as e:
            print(f"   â””â”€ âŒ Hata: {e}")
            import traceback
            traceback.print_exc()

    # Ã–zet
    print("\n" + "=" * 60)
    print("SONUÃ‡")
    print("=" * 60)

    total_main = sum(r['main_count'] for r in results)
    total_sub = sum(r['sub_count'] for r in results)

    print(f"Ä°ÅŸlenen PDF: {len(results)}")
    print(f"Toplam Ana KazanÄ±m: {total_main}")
    print(f"Toplam Alt KazanÄ±m: {total_sub}")
    print(f"Ã‡Ä±ktÄ± klasÃ¶rÃ¼: {output_dir}")
    print("=" * 60)


if __name__ == "__main__":
    main()
